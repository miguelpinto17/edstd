{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2704de0-060b-4fb6-987c-663eecbe726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from delta import *\n",
    "from pyspark.sql.functions import expr, round, col\n",
    "from pyspark.sql.types import DoubleType, StringType, StructField, StructType, IntegerType\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "warehouse_location = 'hdfs://hdfs-nn:9000/warehouse'\n",
    "\n",
    "builder = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Python Spark DataFrames and SQL\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .enableHiveSupport() \\\n",
    "\n",
    "spark = builder.getOrCreate() #spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55407cff-cb46-4315-a10f-7ebcfa372bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_path = \"hdfs://hdfs-nn:9000/projeto/bronze/StatsSeries_Time.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e1a882-e914-4ddc-ae63-ca4afb6a9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SeriesCode: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n",
      "+-----------------+----+--------------------+\n",
      "|       SeriesCode|Year|         Description|\n",
      "+-----------------+----+--------------------+\n",
      "|SP.DYN.LE60.MA.IN|1962|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1962|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1967|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1967|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1972|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1972|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1977|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1977|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1982|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1982|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1987|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1987|The data refer to...|\n",
      "|      SP.UWT.TFRT|1990|Averages for regi...|\n",
      "|      SP.DYN.WFRT|1990|Averages for regi...|\n",
      "|   SH.FPL.SATM.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.ANV4.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.ANVC.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.BRTC.ZS|1990|Averages for regi...|\n",
      "|   SP.DYN.CONM.ZS|1990|Averages for regi...|\n",
      "|   SP.DYN.CONU.ZS|1990|Averages for regi...|\n",
      "+-----------------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read without header\n",
    "stats = spark.read.option(\"header\", True) \\\n",
    "    .csv(hdfs_path)\n",
    "\n",
    "stats = stats.withColumnRenamed(\"DESCRIPTION\",\"Description\")\n",
    "\n",
    "stats = stats.drop(\"_c3\")\n",
    "\n",
    "stats = stats.withColumn(\"Year\", expr(\"substring(Year, 3, length(Year))\")) #Delete the first and secound chars from the Year String (YR)\n",
    "stats = stats.withColumn(\"Year\", col(\"Year\").cast(\"int\")) #Make the col Year type Integer \n",
    "\n",
    "stats.printSchema()\n",
    "stats.show()\n",
    "#stats.toPandas() \n",
    "#Usar o comando acima para uma melhor pré-visualização da tabela\n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField(\"SeriesCode\", StringType(), True),        \n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "])\n",
    "\n",
    "stats \\\n",
    "    .write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"hdfs://hdfs-nn:9000/warehouse/projeto.db/StatsSeries_Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13568a6f-d265-43e6-a3eb-6370cfc822c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+--------------------+\n",
      "|       SeriesCode|Year|         Description|\n",
      "+-----------------+----+--------------------+\n",
      "|SP.DYN.LE60.MA.IN|1962|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1962|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1967|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1967|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1972|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1972|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1977|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1977|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1982|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1982|The data refer to...|\n",
      "|SP.DYN.LE60.MA.IN|1987|The data refer to...|\n",
      "|SP.DYN.LE60.FE.IN|1987|The data refer to...|\n",
      "|      SP.UWT.TFRT|1990|Averages for regi...|\n",
      "|      SP.DYN.WFRT|1990|Averages for regi...|\n",
      "|   SH.FPL.SATM.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.ANV4.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.ANVC.ZS|1990|Averages for regi...|\n",
      "|   SH.STA.BRTC.ZS|1990|Averages for regi...|\n",
      "|   SP.DYN.CONM.ZS|1990|Averages for regi...|\n",
      "|   SP.DYN.CONU.ZS|1990|Averages for regi...|\n",
      "+-----------------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM projeto.StatsSeries_Time\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9236c-3ff4-48cc-972a-846abf4891ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
